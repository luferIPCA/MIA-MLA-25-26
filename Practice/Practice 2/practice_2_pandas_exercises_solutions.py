# -*- coding: utf-8 -*-
"""Practice_2_Pandas_Exercises_Solutions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R5yIRMNUccbtMj8rNWAYFX2WULaPTGfP

# Masters' in Applied Artificial Intelligence
## Machine Learning Algorithms Course (MLA)

Notebooks for MLA course

by [*lufer*](mailto:lufer@ipca.pt)

(2025)

---

# Pandas Practice II (solutions)

This notebook offers a set of solutions to the different tasks of Practice II exercises.

It should be noted there may be more than one different way to answer a question or complete an exercise.

Exercises are based off (and directly taken from) the quick introduction to pandas notebook.

Different tasks will be detailed by comments or text.

For further reference and resources, it's advised to check out the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/).

by lufer

**Contents**

1. [Series](#scrollTo=C1HSirGalYXR&line=2&uniqifier=1)

2. [Dataframes](#scrollTo=sRXI_OF6lYXT&line=1&uniqifier=1)
"""

#mouning local drive
from google.colab import drive
drive.mount('/content/gdrive')

# Import pandas
import pandas as pd

"""## Series"""

# Create a series of three different colours
colours = pd.Series(["Blue", "Red", "White"])

# View the series of different colours
colours

# Create a series of three different car types and view it
cars = pd.Series(["BMW", "Toyota", "Honda"])
cars

#Joinning Series
car_color_ser = pd.concat([cars, colours], axis=1)
print(car_color_ser)

car_color_ser.dtypes

# Combine the Series of cars and colours into a DataFrame
car_data = pd.DataFrame({"Car make": cars,
                         "Colour": colours})
car_data

# Again:
#Create a Series of different numbers and find the mean of them
series = pd.Series([999, 22203, 43920])
series.mean()

# Create a Series of different numbers and find the sum of them
series = pd.Series([482392, 34994, 22])
series.sum()

"""## Dataframes"""

path="/content/gdrive/MyDrive/Colab Notebooks/MIAA - ML - 2025-2026/Practices/Practices 2 - Pandas Exercises/"

# Import "car-sales.csv" and turn it into a DataFrame

car_sales = pd.read_csv(path+"car_sales.csv")
car_sales
car_original=car_sales.copy()

# Export the DataFrame you created to a .csv file
car_sales.to_csv(path+"exported-car-sales.csv")

# Find the different datatypes of the car data DataFrame
car_sales.dtypes

# Describe your current car sales DataFrame using describe()
car_sales.describe()

# Get information about your DataFrame using info()
car_sales.info()

"""What does it show you?

Looking at *info()* results, we have:

* 10 registers
* Column *Make* has one null value
* Column *Colour* has one null value
* Column *Odometer* has three null value
* Column *Doors* has one null value
* Column *Price* has two null value

Let's check it:
"""

car_sales

# List out all the column names of the car sales DataFrame
car_sales.columns

# Find the length of the car sales DataFrame
len(car_sales)

# Show the first 5 rows of the car sales DataFrame
car_sales.head()

# Show the first 7 rows of the car sales DataFrame
car_sales.head(7)

# Show the bottom 5 rows of the car sales DataFrame
car_sales.tail()

# Use .loc to select the row at index 3 of the car sales DataFrame
car_sales.loc[3]

#show values horizontally
#print(*car_sales.loc[3])
#or
a = car_sales.loc[3]
print(*a)

# Use .iloc to select the row at position 3 of the car sales DataFrame
car_sales.iloc[3]

"""Notice how they're the same? Why do you think this is?

Check the pandas documentation for [.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) and [.iloc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html). Think about a different situation each could be used for and try them out.

See [Appendice](#scrollTo=6UajVMXUxjRb&line=6&uniqifier=1) of this notebbok
"""

#What it does?
car_sales.iloc[[3]]
#it returns a dataframe!

# Select the "Odometer" column from the car sales DataFrame
car_sales["Odometer"]

# Find the mean of the "Odometer (KM)" column in the car sales DataFrame
car_sales["Odometer"].mean()

#what it does?
car_sales["Odometer"] > 100000

# Select the rows with over 100,000 kilometers on the Odometer
car_sales[car_sales["Odometer"] > 100000]

# Create a crosstab of the Make and Doors columns
pd.crosstab(car_sales["Make"], car_sales["Doors"])
#see https://medium.com/geekculture/the-power-of-crosstab-function-in-pandas-for-data-analysis-and-visualization-6c085c269fcd

# Group columns of the car sales DataFrame by the Make column and find the average
car_sales.groupby(["Make"]).mean()
#Qhy the error?
#Column *Price* is not nuumerical
#Column *Colour* is not numerical

# Solution 1:
# Consider only numerical columns
#Group columns of the car sales DataFrame by the Make column and find the average
car_sales.groupby(["Make"]).mean(numeric_only=True)

#or
car_sales.groupby("Make")[["Odometer", "Doors"]].mean()

#or
#car_sales.groupby("Make")[car_sales[["Odometer", "Doors"]].columns].mean()

#or
#car_sales_numeric = car_sales[["Odometer", "Doors"]]
#car_sales.groupby("Make")[car_sales_numeric.columns].mean()

# Commented out IPython magic to ensure Python compatibility.
# Import Matplotlib and create a plot of the Odometer column
# Don't forget to use %matplotlib inline
# %matplotlib inline
import matplotlib.pyplot as plt
car_sales["Odometer"].plot()

# Create a histogram of the Odometer column using hist()
car_sales["Odometer"].hist()

# Try to plot the Price column using plot()
car_sales["Price"].plot()

"""Why didn't it work? Can you think of a solution?

You might want to search for "how to convert a pandas string columb to numbers".

And if you're still stuck, check out this [Stack Overflow question and answer on turning a price column into integers](https://stackoverflow.com/questions/44469313/price-column-object-to-int-in-pandas).

See how you can provide the example code there to the problem here.
"""

# Solution:
# Convert *Price* to numerical
car_sales["Price"] = (car_sales["Price"]
                      .replace(r"\$", "", regex=True)
                      .replace(",", "", regex=True)
                      .astype(float))
#Group columns of the car sales DataFrame by the Make column and find the average
car_sales.groupby("Make")[["Odometer", "Doors", "Price"]].mean()

# Try to plot the Price column using plot()
car_sales["Price"].plot()

"""See more approaches next...

### Approach 1

Converting to integer values! We can loose decimal values!
"""

car_original

#Intial dataframe
car_sales=car_original.copy()
car_sales["Price"]

car_sales.info()

# Remove the two extra zeros at the end of the price column
car_sales["Price"] = car_sales["Price"].str[:-2]
car_sales["Price"]

# Remove the punctuation from price column
car_sales["Price"] = car_sales["Price"].str.replace(r"[\$\,\.]", "", regex=True)  #note, you must set "regex=True"

# Check the changes to the price column
car_sales["Price"]

# Change the datatype of the Price column to integers
car_sales["Price"] = car_sales["Price"].astype(int)
#Why error?
#because cannot convert to "int" NaN values

#If there are NaN values, it must be converted to numerical first
car_sales["Price"] = car_sales["Price"].fillna("0").astype(int)

# Check the changes to the price column
car_sales["Price"]

#or
#convert to float...NaN is convertible...see next approach!
car_sales["Price"] = car_sales["Price"].astype(float)

"""### Approach 2

Working with float values
"""

#get initial dataframe
car_sales=car_original.copy()
car_sales

#If there are NaN values, it must be converted to numerical first
car_sales["Price"] = car_sales["Price"].fillna("0")

# Remove the punctuation from price column
#car_sales["Price"] = car_sales["Price"].str.replace(r"[\$]", "", regex=True)  #note, you must set "regex=True"

car_sales.info()

#Convert in float, rounding the decimal part

# Step 1: Convert categorical to string (if not already)
#car_sales["Price"] = car_sales["Price"].astype(str)

# Step 2: Remove "$"" and replace ","" to keep decimals
car_sales["Price"] = car_sales["Price"].str.replace(r"[\$]", "", regex=True)
car_sales["Price"] = car_sales["Price"].str.replace(r"[,]", ".", regex=True)

# Step 3: Convert values to float
car_sales["Price"] = car_sales["Price"].astype(float)

# Step 4: Round to one decimal place
car_sales["Price"] = car_sales["Price"].round(1)

car_sales["Price"]

"""**Changing text values**"""

# Lower the strings of the Make column
car_sales["Make"].str.lower()

"""If you check the car sales DataFrame, you'll notice the Make column hasn't been lowered.

How could you make these changes permanent?

Try it out.
"""

# Make lowering the case of the Make column permanent
car_sales["Make"] = car_sales["Make"].str.lower()

# Check the car sales DataFrame
car_sales

"""Notice now the Make column stays lowered after reassigning.

# Missing Data
Now let's deal with missing data.
"""

# Import the car sales DataFrame with missing data ("car-sales-missing-data.csv")
car_sales_missing = pd.read_csv(path+"car-sales-missing-data.csv")

# Check out the new DataFrame
car_sales_missing

"""Notice the missing values are represented as `NaN` in pandas DataFrames.

Let's try fill them.
"""

# Fill the Odometer column missing values with the mean of the column inplace
#vers√µes anteriores
#car_sales_missing["Odometer"].fillna(car_sales_missing["Odometer"].mean(), inplace=True)
car_sales_missing["Odometer"]=car_sales_missing["Odometer"].fillna(car_sales_missing["Odometer"].mean())

# View the car sales missing DataFrame and verify the changes
car_sales_missing

# Remove the rest of the missing data inplace
car_sales_missing.dropna(inplace=True)

# Verify the missing values are removed by viewing the DataFrame
car_sales_missing

"""We'll now start to add columns to our DataFrame."""

# Create a "Seats" column where every row has a value of 5
car_sales["Seats"] = 5
car_sales

# Create a column called "Engine Size" with random values between 1.3 and 4.5
# Remember: If you're doing it from a Python list, the list has to be the same length
# as the DataFrame
engine_sizes = [1.3, 4.3, 2.3, 3.3, 3.0, 2.3, 1.4, 1.7, 2.5, 3.1]
car_sales["Engine Size"] = engine_sizes
car_sales

# Create a column which represents the price of a car per kilometer
# Then view the DataFrame
car_sales["Price per KM"] = car_sales["Price"] / car_sales["Odometer"]
car_sales

# Remove the last column you added using .drop()
car_sales = car_sales.drop("Price per KM", axis=1)
car_sales

# Shuffle the DataFrame using sample() with the frac parameter set to 1
# Save the the shuffled DataFrame to a new variable
car_sales_sampled = car_sales.sample(frac=1)
car_sales_sampled

"""Notice how the index numbers get moved around. The [`sample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) function is a great way to get random samples from your DataFrame. It's also another great way to shuffle the rows by setting `frac=1`."""

# Reset the indexes of the shuffled DataFrame
car_sales_sampled.reset_index()

"""Notice the index numbers have been changed to have order (start from 0)."""

# Change the Odometer values from kilometers to miles using a Lambda function
# Then view the DataFrame
car_sales["Odometer"] = car_sales["Odometer"].apply(lambda x: x/1.6)
car_sales

# Change the title of the Odometer (KM) to represent miles instead of kilometers
car_sales = car_sales.rename(columns={"Odometer": "Odometer (Miles)"})
car_sales

"""## Appendices

**Difference Between loc and iloc**

The difference between the *loc* and *.iloc* functions is that the loc function selects rows using row labels (index) whereas the iloc function selects rows using their integer positions (staring from 0 and going up by one for each row).

See the example in: https://discovery.cs.illinois.edu/guides/DataFrame-Fundamentals/dataframe-loc-vs-iloc/

## Extensions

For more exercises, check out the pandas documentation, particularly the [10-minutes to pandas section](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html).

One great exercise would be to retype out the entire section into a Jupyter Notebook of your own.

Get hands-on with the code and see what it does.

The next place you should check out are the [top questions and answers on Stack Overflow for pandas](https://stackoverflow.com/questions/tagged/pandas?sort=MostVotes&edited=true). Often, these contain some of the most useful and common pandas functions. Be sure to play around with the different filters!

Finally, always remember, the best way to learn something new to is try it. Make mistakes. Ask questions, get things wrong, take note of the things you do most often. And don't worry if you keep making the same mistake, pandas has many ways to do the same thing and is a big library. So it'll likely take a while before you get the hang of it.
"""