{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kf9qddTM4D"
      },
      "source": [
        "# Masters' in Applied Artificial Intelligence\n",
        "## Machine Learning Algorithms Course (MLA)\n",
        "\n",
        "Notebooks for MLA course\n",
        "\n",
        "by [*lufer*](mailto:lufer@ipca.pt)\n",
        "\n",
        "(2024)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yc6mD0jVeWN"
      },
      "source": [
        "# Part II - Datasets Manipulation (I)\n",
        "\n",
        "This is the first notebook for datasets manipulation. Cleaning, Normalizing, Initializing are some of the required tasks during dataset preparation for training.\n",
        "\n",
        "**Contents**:\n",
        "\n",
        "1. **Features Engineering**\n",
        "2. **Cleaning Data**\n",
        "3. **Outliers**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-NymupVL02"
      },
      "source": [
        "## Environment preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Rm857IVoPe"
      },
      "source": [
        "### Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA1MzNI4TU_q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLxcgMwJEYA"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFY0ypTJJK9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# it will ask for your google drive credentiaals\n",
        "drive.mount('/content/gDrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrlsXAs4I0AZ"
      },
      "source": [
        "*Loading dataset*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#global path variable\n",
        "path=\"/content/gDrive/MyDrive/Colab Notebooks/MIA - ML - 2024-2025/Datasets/\"\n",
        "#path"
      ],
      "metadata": {
        "id": "l2JGAqJpvdjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRpURt1tI2Sf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "download_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv\"\n",
        "target_csv_path = path+\"nbaAll.csv\"\n",
        "\n",
        "#create a local file with remote csv data\n",
        "response = requests.get(download_url)\n",
        "response.raise_for_status()\n",
        "with open(target_csv_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "print(\"Download ready.\")\n",
        "\n",
        "nba = pd.read_csv(path+\"nbaAll.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba\n"
      ],
      "metadata": {
        "id": "XXdran7P74Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3F4J7bkKVgF"
      },
      "source": [
        "## 1 - Features Engineering\n",
        "\n",
        "Features Engineering means a set of actions to deal with features (columns) of a dataset.\n",
        "\n",
        "It involves selecting, manipulating and transforming raw data into features that can be used in training models.\n",
        "\n",
        "**Feature Engineering Definition**\n",
        "\n",
        "*Feature engineering is the process of selecting, manipulating and transforming raw data into features that can be used in supervised learning. It consists of five processes: feature creation, transformations, feature extraction, exploratory data analysis and benchmarking.*\n",
        "\n",
        "Processes involving:\n",
        "\n",
        "\n",
        "*   Feature creation (adding or removing some features)\n",
        "*   Transformations\n",
        "*   Feature extraction\n",
        "*   Exploratory data analysis\n",
        "*   Benchmark\n",
        "\n",
        "Concrete actions:\n",
        "\n",
        "*   Inputation (missing values: categorical and numerical)\n",
        "*   Handling outliers (Removing, Replacing values, Discretization)\n",
        "*   Log Transform (handle confusing data)\n",
        "*   One-Hot Encoding (unique value for each possible case)\n",
        "*   Scaling (Normalization, Standardization )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jNC8uv0KgHd"
      },
      "outputs": [],
      "source": [
        "#checking dataset structure\n",
        "nba.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba.head()"
      ],
      "metadata": {
        "id": "RxZdMfFQ8RoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Filtering columns with \"isin\"*"
      ],
      "metadata": {
        "id": "7VMLnNsgAUbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbaYear = nba[nba[\"year_id\"].isin([1948, 1949])]\n",
        "nbaYear"
      ],
      "metadata": {
        "id": "YRRg1d3W8pbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Get first N columns from a dataframe*"
      ],
      "metadata": {
        "id": "5jBNP6w2_8N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=3\n",
        "aux = nba.iloc[:,:n]\n",
        "aux"
      ],
      "metadata": {
        "id": "GvIW1dm--DhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Get last N columns from a dataframe*"
      ],
      "metadata": {
        "id": "pqQolfQG_2un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aux = nba.iloc[:,-3:]\n",
        "aux"
      ],
      "metadata": {
        "id": "old4dp6q-nA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3iNajqoK6cA"
      },
      "source": [
        "### Deriving new Feature\n",
        "\n",
        "(this will be more explored later on *Categorical to Numerical* section)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create new Feature (column)*"
      ],
      "metadata": {
        "id": "E9TRIHxxBA-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba[\"date_played\"] = pd.to_datetime(nba[\"date_game\"])\n",
        "#nba\n",
        "#nba.columns"
      ],
      "metadata": {
        "id": "Q9PVU1sfAsQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create new Feature from calculus over others*"
      ],
      "metadata": {
        "id": "-tWwn2yUID6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#See https://www.plus2net.com/python/pandas-dt-timedelta64.php\n",
        "from datetime import date\n",
        "today = pd.to_datetime(date.today())\n",
        "#new column\n",
        "nba['DaysCPassed'] = (today-nba['date_played']) / np.timedelta64(1, 'D')\n",
        "nba.shape"
      ],
      "metadata": {
        "id": "QgFpbtN7CeES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nba.DaysCPassed.max()"
      ],
      "metadata": {
        "id": "SzFuecvUIn3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdBp7-zKJ7pj"
      },
      "source": [
        "### Change features names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk7qiuoJLJgX"
      },
      "outputs": [],
      "source": [
        "renamedNba = nba.rename(columns={\"DaysCPassed\": \"DaysPassed\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwzdfQr_LbH0"
      },
      "outputs": [],
      "source": [
        "renamedNba.info()\n",
        "print('-'*50)\n",
        "nba.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxPJJYUmL5H2"
      },
      "source": [
        "### Deleting Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Delete a particular Feature (column)*"
      ],
      "metadata": {
        "id": "Mp9WUNTqBusH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "renamedNba.info()"
      ],
      "metadata": {
        "id": "WnkvRc5rwakg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "renamedNba = renamedNba.drop(columns=['notes'])\n",
        "#or\n",
        "#renamedNba.drop(['notes'],axis=1)\n",
        "\n",
        "renamedNba.info()\n",
        "print('-'*50)\n",
        "renamedNba.info()\n"
      ],
      "metadata": {
        "id": "z6Veu-NEBeI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laaIfiSfVPK9"
      },
      "source": [
        "### Changing the Data Type of Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9rtxPJPP5R-"
      },
      "outputs": [],
      "source": [
        "df = nba.copy()\n",
        "df.info()\n",
        "#df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Convert column types*"
      ],
      "metadata": {
        "id": "hECg4AoHVAdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba[\"date_played\"] = pd.to_datetime(nba[\"date_game\"])"
      ],
      "metadata": {
        "id": "xVmY08NOUqid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Identify unique values*"
      ],
      "metadata": {
        "id": "k37Je0HzR-ME"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4yHpqz7VVM1"
      },
      "outputs": [],
      "source": [
        "a=df[\"game_location\"].unique()\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Counting distinct values*"
      ],
      "metadata": {
        "id": "tmJG4UZWSdKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=df[\"game_location\"].nunique()\n",
        "a"
      ],
      "metadata": {
        "id": "Ff8UcOTYSgBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Occurences*"
      ],
      "metadata": {
        "id": "nH8mnxzTS8Ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVLKL1J2Vhba"
      },
      "outputs": [],
      "source": [
        "df['team_id'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vf4jAgyXXs_"
      },
      "source": [
        "Make colunms Category type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNu2sTVQV0nK"
      },
      "outputs": [],
      "source": [
        "t= pd.Categorical(nba['team_id'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcabHdnYWUjb"
      },
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XciES3d-WWG_"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UnR8HIXWmZI"
      },
      "outputs": [],
      "source": [
        "df[\"game_location\"] = pd.Categorical(df[\"game_location\"])\n",
        "df[\"game_location\"].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP5AAgR1WyDv"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grouping features\n",
        "\n",
        "Grouping allow to merge columns, applying aggregating functions: mean, average, sum, etc..."
      ],
      "metadata": {
        "id": "bshH5MkZfB6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba.groupby(\"fran_id\", sort=False)[\"pts\"].sum()\n",
        "# Expected:\n",
        "# fran_id\n",
        "# Huskies           3995\n",
        "# Knicks          582497\n",
        "# Stags            20398\n",
        "# Falcons           3797\n",
        "# Capitols         22387"
      ],
      "metadata": {
        "id": "R1HPN50afDCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Cleaning Data\n",
        "\n",
        "Cleaning data means actions to overcome eventual existing problems with the data. It could be necessary to handle null values, duplicates, imbalanced datasets, outliers, etc."
      ],
      "metadata": {
        "id": "AyzAxMaDAoP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKk-sZnoXk5c"
      },
      "outputs": [],
      "source": [
        "nba.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27KLSA8iYUQl"
      },
      "source": [
        "### Inputting Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id31DXthYWbV"
      },
      "source": [
        "\n",
        "Missing values can be handle by:\n",
        "1. by removing (just that!)\n",
        "2. by replacing (inputing):\n",
        "\n",
        "* numeric values with \"median\" (if not normalized or have outliers)\n",
        "* numeric values with \"mean\" (if normally distributed data)\n",
        "* categorical values with \"mode\"\n",
        "\n",
        "\n",
        "> **Note**: median is better than average because it is not susceptible to discrepancies in values. Otherwise, what would happen if a millionaire appeared in the average calculation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets avoid *null-values*\n",
        "\n",
        "The current nba dataset has null  values (*Null/None/ Nan Values*) (how to prove that?).\n",
        "\n",
        "The column \"*motes*\" has only 5424 *non-null* values. All remain columns have 126314 values..\n",
        "\n",
        "(try to get this results)"
      ],
      "metadata": {
        "id": "U3S7Bp7LLS31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let analythe the following example:"
      ],
      "metadata": {
        "id": "gApfRNftMM2R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STRTIOVFX_St"
      },
      "outputs": [],
      "source": [
        "#import pandas as pd\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [25, 31, 25, None, 27],\n",
        "        'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "        'Salary': [50000, None, 30000, 40000, 60000]}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2YtG8fRZfmg"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAf4U2YPlscW"
      },
      "source": [
        "*It* is easy to realize that *Name* has 5  *non-null* values, but the other columns have only 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRS3_eFZZiQn"
      },
      "outputs": [],
      "source": [
        "#preserve original datatset\n",
        "dfCopy = df.copy()\n",
        "dfCopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Identify the Missing Values*\n",
        "\n",
        "The missing values are converted by default. The functions to identify these missing values are:\n",
        "\n",
        "*   **isnull()**\n",
        "*   **notnull()**\n",
        "\n",
        "\n",
        "The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n",
        "\n",
        "\"True\" means the value is a missing value while \"False\" means the value is not a missing value."
      ],
      "metadata": {
        "id": "W6U1ssbmSglq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data = dfCopy.isnull()\n",
        "missing_data.head(5)"
      ],
      "metadata": {
        "id": "0HC9YL7HTFd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cToibVApD5A"
      },
      "source": [
        "### Replacing missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace null values of *Age* feature by *Unknown*"
      ],
      "metadata": {
        "id": "8cVvTldwQhbF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTKVzOg4jE6i"
      },
      "outputs": [],
      "source": [
        "dfCopy[\"Age\"]= dfCopy[\"Age\"].fillna(\\\n",
        "                     value=\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vsRIhHXpvdW"
      },
      "outputs": [],
      "source": [
        "dfCopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Replace null values by a particular value*"
      ],
      "metadata": {
        "id": "synXoiD4QU4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izXQ_wazqKYj"
      },
      "outputs": [],
      "source": [
        "dfCopy.fillna({'Age':'Unknown', 'Gender': 'Other'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIYTXPC2rLUw"
      },
      "outputs": [],
      "source": [
        "display(dfCopy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace the \"?\" symbol with *NaN* so the dropna() can remove the missing values:"
      ],
      "metadata": {
        "id": "vtH-F78rQ2qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=dfCopy.replace('?',np.NaN)"
      ],
      "metadata": {
        "id": "mdYX9LKQQ2DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su5dSqx7sY9V"
      },
      "source": [
        "Fill **number features** with the *mean* value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-DQ_LhKtNVn"
      },
      "outputs": [],
      "source": [
        "#reset dfCopy\n",
        "dfCopy = df.copy()\n",
        "#dfCopy\n",
        "#dfCopy.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okbTfd5Osdgn"
      },
      "outputs": [],
      "source": [
        "#Using mean() function to input the NaN values using fillna\n",
        "dfCopy.fillna({'Salary':dfCopy['Salary'].mean()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTHq7firtj5-"
      },
      "outputs": [],
      "source": [
        "dfCopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF46HeHUr_5i"
      },
      "source": [
        "Fill number features with the *mode* value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ7HUcLLrYiN"
      },
      "outputs": [],
      "source": [
        "#Using mode() function to input the NaN values using fillna\n",
        "dfCopy.fillna({'Salary':dfCopy['Salary'].mode()[0]}, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill categorical features with the *mode* value"
      ],
      "metadata": {
        "id": "-oQoimUBP5EI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y2DLLSMsMRk"
      },
      "outputs": [],
      "source": [
        "mode=dfCopy['Age'].mode()[0] #mode()[0] gives the first mode if multiple exist\n",
        "mode\n",
        "#age_mode = dfCopy['Age'].mode()[0]\n",
        "#age_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3fnKc6wsNxs"
      },
      "outputs": [],
      "source": [
        "#Replace Age NaN values with the mode()\n",
        "#dfCopy=dfCopy.fillna({'Age':mode, 'Gender':'Other'})\n",
        "dfCopy['Age']=dfCopy['Age'].fillna(mode)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dfCopy=dfCopy.fillna({'Age':mode})\n",
        "dfCopy"
      ],
      "metadata": {
        "id": "hfjKyB_WQQJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_xLOgdhaIxL"
      },
      "source": [
        "### See the *null* values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ldO84AZzUH"
      },
      "outputs": [],
      "source": [
        "n1 = dfCopy.isnull().any(axis=1)\n",
        "n1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyaaQUqQahic"
      },
      "source": [
        "### Get only the *null* values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLWvOi7YaXF0"
      },
      "outputs": [],
      "source": [
        "nullRows = dfCopy[n1]\n",
        "nullRows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwJP-OENbDcQ"
      },
      "source": [
        "### Get only the *non-null* values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke1ydhkQax6L"
      },
      "outputs": [],
      "source": [
        "n2 = dfCopy.notnull().all(axis=1)\n",
        "n2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ZclJ8DbYm_"
      },
      "outputs": [],
      "source": [
        "nonNullRows = dfCopy[n2]\n",
        "nonNullRows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZHJjI-7cL28"
      },
      "source": [
        "### Checking *Null Values* using Query Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6qrjibcuqU"
      },
      "source": [
        "In this example, the != operator compare the column values with themselves, which returns *True* if the value is *null*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTswCuLBbr-0"
      },
      "outputs": [],
      "source": [
        "nullRows = dfCopy.query('Age != Age or Gender != Gender or Salary != Salary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHnjalClcU9K"
      },
      "outputs": [],
      "source": [
        "nullRows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsXDSybLmMRx"
      },
      "source": [
        "###  Remove rows with missing values\n",
        "\n",
        "The easiest way to deal with records containing missing values (incomplete records) is to ignore them!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4KHHBF4mQOR"
      },
      "outputs": [],
      "source": [
        "dfCopy.shape\n",
        "#dfCopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7cg7CB-mX7-"
      },
      "outputs": [],
      "source": [
        "#default axis=0 (index==rows)\n",
        "rowsWithoutMissingData = dfCopy.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm1_87IOmlEJ"
      },
      "outputs": [],
      "source": [
        "rowsWithoutMissingData.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rowsWithoutMissingData"
      ],
      "metadata": {
        "id": "NuxCBkliX4jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcL7oHBYnm4o"
      },
      "source": [
        "### Remove *Features* with null-values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vca3PHzoA9o"
      },
      "source": [
        "Remove problematic columns if they’re not relevant for your analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVMKkkcPnmpZ"
      },
      "outputs": [],
      "source": [
        "#Features==Columns (axis 1)\n",
        "dataWithoutMissingColumns = dfCopy.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUgTeZ99okwn"
      },
      "outputs": [],
      "source": [
        "dataWithoutMissingColumns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba.info()"
      ],
      "metadata": {
        "id": "Xe13iGdsYrPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change *Null Values*"
      ],
      "metadata": {
        "id": "bO-9MNMHZbtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html\n",
        "data_with_default_notes = nba.copy()\n",
        "data_with_default_notes[\"notes\"].fillna(value=\"no notes at all\", inplace=True)\n",
        "data_with_default_notes[\"notes\"].describe()\n",
        "# Expected:\n",
        "# count              126314\n",
        "# unique                232\n",
        "# top       no notes at all\n",
        "# freq               120890\n",
        "# Name: notes, dtype: object"
      ],
      "metadata": {
        "id": "MDWtLtbLYjbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invalid Values"
      ],
      "metadata": {
        "id": "4qOosR2TaUkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba[nba[\"pts\"] == 0]"
      ],
      "metadata": {
        "id": "3cJg5HTHaXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inconsistencies Between Values in Different Columns"
      ],
      "metadata": {
        "id": "H3DxJlYBamSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba[(nba[\"pts\"] > nba[\"opp_pts\"]) & (nba[\"game_result\"] != \"W\")].empty\n",
        "# Expected:\n",
        "# True"
      ],
      "metadata": {
        "id": "1rb58BuEapS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nba[(nba[\"pts\"] < nba[\"opp_pts\"]) & (nba[\"game_result\"] != \"L\")].empty\n",
        "# Expected:\n",
        "# True"
      ],
      "metadata": {
        "id": "-E7rlFxsaz1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Outliers"
      ],
      "metadata": {
        "id": "BxebWzwFSMRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding outliers"
      ],
      "metadata": {
        "id": "E4_JSL16L3Rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing outliers, i.e., values very distant from the standard deviation.\n",
        "\n",
        "See\n",
        "* [How To Find Outliers in Data Using Python](https://careerfoundry.com/en/blog/data-analytics/how-to-find-outliers/)\n",
        "* [What Is an Outlier](https://careerfoundry.com/en/blog/data-analytics/what-is-an-outlier/#what-is-an-outlier)\n",
        "* [How to Find Outliers in a Data Set](https://humansofdata.atlan.com/2017/10/how-to-find-outliers-data-set/)\n",
        "\n",
        "Outliers are the extreme values within the dataset. They can be found in two ways:\n",
        "* by using statistical calculs ( with standard deviation calculation).\n",
        "* grapically (boxplot)"
      ],
      "metadata": {
        "id": "BtBUb78YST5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recover original df\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [25, 31, 25, None, 27],\n",
        "        'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "        'Salary': [50000, None, 30000, 40000, 60000]}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "tlDuyh4-09vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gBIGm0dLVfGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R3UfeGP64ukc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A- Find outliers statisticaly - with *describe*()**"
      ],
      "metadata": {
        "id": "3YGwFSuRTwAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "X_AoCgyRTw3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all standard deviations\n",
        "std_devs = df.std(numeric_only=True,ddof=1)\n",
        "std_devs"
      ],
      "metadata": {
        "id": "qrAMtGO5W5GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()['Salary']"
      ],
      "metadata": {
        "id": "3PD1DpnrVFbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4mdDlIMn4tSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B - Find outliers statisticaly - with std()**\n",
        "\n",
        "> To identify potential outliers using the standard deviation method, you can calculate the mean and standard deviation of a numeric column and check if any values lie outside the range defined by μ±kσ, where μ is the mean, σ is the standard deviation, and\n",
        "k is a chosen threshold (commonly k=3).\n",
        "\n",
        "Attention: To get better results, remember:\n",
        "\n",
        "1. Remove NaN values\n",
        "2. Sort the entire DataFrame by intended feature\n"
      ],
      "metadata": {
        "id": "ALovFkamUVYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the standard deviations with *std()* and *mean()*"
      ],
      "metadata": {
        "id": "8_Ow3wZY_Q3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyse only the Salary\n",
        "desv = df['Salary'].std()\n",
        "desv"
      ],
      "metadata": {
        "id": "7zKeJRahUWSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = df['Salary'].mean()\n",
        "mean"
      ],
      "metadata": {
        "id": "BaQnaZhA_u1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find uncommon values, like greater 2 or 3 times (threshold) the std\n",
        "df.loc[df['Salary']>= mean + 3 * desv, 'Salary'].count()\n",
        "#no outliers"
      ],
      "metadata": {
        "id": "bzJfDaS2UkDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another perspective:"
      ],
      "metadata": {
        "id": "9z3tMCDy_aeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the mean and standard deviation for 'Salary' and 'Age'\n",
        "for column in ['Salary', 'Age']:\n",
        "    mean = df[column].mean()\n",
        "    std_dev = df[column].std()\n",
        "    threshold = 3  # Common threshold for outlier detection\n",
        "\n",
        "    # Define the range for outliers\n",
        "    lower_bound = mean - threshold * std_dev\n",
        "    upper_bound = mean + threshold * std_dev\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    print(f\"Analysis for {column}:\")\n",
        "    print(f\"Mean: {mean}, Std Dev: {std_dev}\")\n",
        "    print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
        "    print(f\"Outliers:\\n{outliers}\\n\")"
      ],
      "metadata": {
        "id": "5LydApYt2oFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, according to std, we don't have outliers!\n",
        "\n",
        "However, this approach works better for columns without missing values. For Salary and Age, missing values are ignored automatically by pandas."
      ],
      "metadata": {
        "id": "6iWsHV-T_Loq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9zQEv-wG4q0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C - See it Graphically with BoxPLot and IRQ**\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Compute Quartiles:\n",
        "* Q1: The 25th percentile (lower quartile).\n",
        "* Q3: The 75th percentile (upper quartile).\n",
        "\n",
        "\n",
        "2. Calculate IQR:\n",
        "* IQR=Q3-Q1\n",
        "\n",
        "\n",
        "3. Outlier Range:\n",
        "* Lower Bound: Q1-1.5xIQR (very common to use 3)\n",
        "* Upper Band: Q1+1.5*IQR. (very common to use 3)\n",
        "\n",
        "4. Outliers:\n",
        "* Any values below the lower bound or above the upper bound are considered outliers."
      ],
      "metadata": {
        "id": "exUXvs4mz034"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7tFpj9mX429c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "dOIIcwXeXKjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an horizontal box-plot\n",
        "fig = px.box(df, x='Salary')\n",
        "fig.update_xaxes(tickangle=-90)  # Rotate labels by -45 degrees\n",
        "fig.update_layout(width=700, height=500)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cgAYUeO5tyXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a box-plot\n",
        "#fig = px.box(df, x='Salary')\n",
        "fig = px.box(df, y='Salary', title=\"Vertical Box Plot of Salaries\", labels={'Salary': 'Salary ($)'})\n",
        "fig.update_layout(width=500, height=700)  # Specify width and height in pixels\n",
        "fig.show()\n",
        "\n",
        "#what this means\n",
        "#fig = px.box(df, y='Salary', x='Age', title=\"Vertical Box Plot of Salaries\", labels={'Salary': 'Salary ($)', 'Job': 'Job Role'})"
      ],
      "metadata": {
        "id": "7rlmPuUiXUZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or\n",
        "# Create a boxplot for Salary\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.boxplot(df['Salary'].dropna(), vert=False, patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
        "            whiskerprops=dict(color='blue'), capprops=dict(color='blue'),\n",
        "            medianprops=dict(color='red'))\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Boxplot of Salary\", fontsize=14)\n",
        "plt.xlabel(\"Salary\", fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EZdqShj_YNAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxes Analysis:\n",
        "\n",
        "Boxplot Components:\n",
        "\n",
        "* The box represents the interquartile range (IQR).\n",
        "* The line inside the box represents the median.\n",
        "* The whiskers extend to the smallest and largest data points within 1.5 x IQR from Q1 and Q3, respectively.\n",
        "* Points outside the whiskers are plotted individually as outliers.\n",
        "\n",
        "Expected Result:\n",
        "\n",
        "* The salaries (30000, 40000, 50000, 60000) fall within the whiskers.\n",
        "* No individual points outside the whiskers indicate no outliers in this dataset.\n",
        "\n",
        "Final remarks:\n",
        "\n",
        "* No points lie outside the whiskers, confirming there are no outliers in the Salary data"
      ],
      "metadata": {
        "id": "QoU9xGOqYbmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another tools:\n",
        "\n",
        "Using Scatter Plots:"
      ],
      "metadata": {
        "id": "DSfJifQEI7jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(5, 6))\n",
        "plt.scatter(df.index, df['Salary'], color='blue', label='Salary')\n",
        "plt.axhline(y=df['Salary'].median(), color='red', linestyle='--', label='Median')\n",
        "plt.title(\"Scatter Plot of Salary\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Salary\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7CyBrQQYI66h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Histogram"
      ],
      "metadata": {
        "id": "kQB1X8UiJuut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the median\n",
        "median_value = df['Salary'].median()\n",
        "\n",
        "# Histogram\n",
        "plt.figure(figsize=(5, 6))\n",
        "plt.hist(df['Salary'], bins=10, color='skyblue', edgecolor='black')\n",
        "# Add a vertical line for the median\n",
        "plt.axvline(median_value, color='red', linestyle='--', linewidth=2, label=f'Median: {median_value}')\n",
        "\n",
        "# Labels, Title, and Legend\n",
        "plt.title(\"Histogram of Salary with Median\")\n",
        "plt.xlabel(\"Salary\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CuELuCs_JruG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3m7BOECc5Sbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What happens if the the salary of Eva is 600000?*\n"
      ],
      "metadata": {
        "id": "zDjgyphl46Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recover original df\n",
        "\n",
        "data2 = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [25, 31, 25, None, 27],\n",
        "        'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "        'Salary': [50000, None, 30000, 40000, 600000]}\n",
        "\n",
        "df2 = pd.DataFrame(data2)\n",
        "df2"
      ],
      "metadata": {
        "id": "F2i6DE465B6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets use IQR IQR=Q3-Q1)"
      ],
      "metadata": {
        "id": "LIV09H3I0f7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "data2 = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 31, 25, None, 27],\n",
        "    'Gender': ['F', 'M', None, 'M', 'F'],\n",
        "    'Salary': [50000, None, 30000, 40000, 600000]\n",
        "}\n",
        "\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Drop NaN values and sort the entire DataFrame by 'Salary'\n",
        "df_sorted = df2.dropna(subset=['Salary']).sort_values(by='Salary')\n",
        "\n",
        "# Calculate Q1 (25th percentile) on the 'Salary' column\n",
        "q1 = df_sorted['Salary'].quantile(0.25)\n",
        "q3 = df2['Salary'].quantile(0.75)\n",
        "\n",
        "# IQR=Q3−Q1\n",
        "iqr=q3-q1\n",
        "\n",
        "print(\"Q1=\",q1)\n",
        "print(\"Q3=\",q3)\n",
        "print(\"IRQ=\",iqr)\n"
      ],
      "metadata": {
        "id": "YkeR7HrHJox6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Box plot for Salary\n",
        "fig = px.box(df2, y='Salary', title=\"Box Plot for Salary (Outlier Detection)\", labels={'Salary': 'Salary ($)'})\n",
        "fig.update_layout(width=500, height=700)  # Specify width and height in pixels\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yeS-EUeN6Hki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarks:\n",
        "* no point after or before the wiskers.\n",
        "* Thus, no outliers\n",
        "\n",
        "\n",
        "**Final Explanation:**\n",
        "\n",
        "* 600000 afects both, the std and the mean!\n",
        "\n",
        "* Standard deviation works well if the data is normalized\n",
        "* Standard deviation is sensitive to extreme values (outliers - tey distorce both μ (mean) and σ (standard deviation),\n",
        "* Thus, std is less effective in datasets with large variability or skewed distributions.\n",
        "* In these cases use more robust methods like ***Median Absolute Deviation (MAD)*** for outlier detection."
      ],
      "metadata": {
        "id": "3oS6yr9K5tA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8py7bvLzAEtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "What happens if the salaray values are:\n",
        "\n",
        "\n",
        "'Salary': [50000, 40000, 30000, 70000, 1000000]\n",
        "\n"
      ],
      "metadata": {
        "id": "bKLirb5-93if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r8zkygA6AGzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Handling outliers\n",
        "\n",
        "Analysing outliers, i.e., values very distant from the standard deviation.\n",
        "\n",
        "See\n",
        "* [How To Find Outliers in Data Using Python](https://careerfoundry.com/en/blog/data-analytics/how-to-find-outliers/)\n",
        "* [What Is an Outlier](https://careerfoundry.com/en/blog/data-analytics/what-is-an-outlier/#what-is-an-outlier)\n",
        "* [How to Find Outliers in a Data Set](https://humansofdata.atlan.com/2017/10/how-to-find-outliers-data-set/)\n",
        "\n",
        "\n",
        "Outliers are the extreme values within the dataset."
      ],
      "metadata": {
        "id": "zXkaRCL4MqqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let analyse a new dataset"
      ],
      "metadata": {
        "id": "pIRh5hazMxZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the dataset**\n",
        "\n"
      ],
      "metadata": {
        "id": "xHAZm4hNM7KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath=\"/content/gDrive/MyDrive/Colab Notebooks/MIA - ML - 2024-2025/Datasets/\""
      ],
      "metadata": {
        "id": "YNo34kA-M7KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(filePath+'credit_simple.csv', sep=';')\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "FhvAe858M7KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "zkV9CF5qM7KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5Zj8DM8uM7KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the dataset**\n",
        "\n",
        "* Identify the dependent variable\n",
        "* Isolate the feature \"CLASSE\""
      ],
      "metadata": {
        "id": "F3OlISxhM7KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['CLASSE']\n",
        "X = dataset.iloc[:,:-1] #all raws, allcolumns from 0 to n-1"
      ],
      "metadata": {
        "id": "-RZnwmVgM7KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find outliers statisticaly - with *describe*()**"
      ],
      "metadata": {
        "id": "JOnBxsUDNmbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "id": "wjR0m8lUNmbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.describe()['SALDO_ATUAL']\n",
        "#Note:\n",
        "# funtion describe() calculates the Sample standard deviation\n",
        "# function std() calcules the Population standard deviation\n",
        "# to make it equal, std(ddof=1)\n",
        "# \"ddof\" stands for \"Delta Degrees of Freedom\""
      ],
      "metadata": {
        "id": "yxeZVNsfNmbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing it:\n",
        "\n",
        "Statistic\t| Value\n",
        "----------|----------\n",
        "count\t| 993 (number of entries)\n",
        "mean | 24,258,570 (average value)\n",
        "std\t| 688,349,600 (standard deviation)\n",
        "min\t| 250 (minimum value)\n",
        "25%\t| 1,371 (first quartile, lower 25%)\n",
        "50%\t| 2,323 (median, middle value)\n",
        "75%\t| 3,976 (third quartile, upper 25%)\n",
        "max\t| 21,544,410,000 (maximum value)\n",
        "\n",
        "Notes:\n",
        "1. Disparity Between std and Quartiles:\n",
        "\n",
        "* The std (standard deviation) is 688,349,600, which is an extremely large value compared to the interquartile range (IQR), from 1,371 (25%) to 3,976 (75%).\n",
        "* This suggests that the dataset has outliers or extreme values, especially near the maximum.\n",
        "\n",
        "2. Skewness:\n",
        "\n",
        "* The *mean* (24,258,570) is much larger than the *median* (2,323), indicating that the data is right-skewed, likely due to extreme high values (e.g., the maximum: 21,544,410,000).\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Considering SALDO_ATUAL, the minimum value (250.000) is very small compared with std (688,349,600). There are outliers, definitely!"
      ],
      "metadata": {
        "id": "8l2G4kjKN2_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['SALDO_ATUAL'].max()"
      ],
      "metadata": {
        "id": "ZwspG24WEBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.sort_values('SALDO_ATUAL',ascending=False)['SALDO_ATUAL']"
      ],
      "metadata": {
        "id": "e9uNtlBodx9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "# Calculate the mean and standard deviation for 'SALDO_ATUAL'\n",
        "column='SALDO_ATUAL'\n",
        "mean = X[column].mean()\n",
        "std_dev = X[column].std()\n",
        "threshold = 3  # Common threshold for outlier detection\n",
        "\n",
        "# Define the range for outliers\n",
        "lower_bound = mean - threshold * std_dev\n",
        "upper_bound = mean + threshold * std_dev\n",
        "\n",
        "# Identify outliers\n",
        "outliers = X[(X[column] < lower_bound) | (X[column] > upper_bound)]\n",
        "#outliers = X[(X[column] > upper_bound)]\n",
        "\n",
        "print(f\"Analysis for {column}:\")\n",
        "print(f\"Mean: {mean}, Std Dev: {std_dev}\")\n",
        "print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
        "print(f\"Outliers:\\n{outliers['SALDO_ATUAL']}\\n\")"
      ],
      "metadata": {
        "id": "6aop9OWhdNoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two outliers!"
      ],
      "metadata": {
        "id": "CESmvWY5eg1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find outliers statisticaly - with std()**\n",
        "\n",
        "Calculating standard deviations with *std*()"
      ],
      "metadata": {
        "id": "7MLFQ3SeN2_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all standard deviations\n",
        "std_devs = X.std(numeric_only=True,ddof=1)\n",
        "std_devs"
      ],
      "metadata": {
        "id": "Bw-ZcGZsN2_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyse only  SALDO_ATUAL\n",
        "desv = X['SALDO_ATUAL'].std()\n",
        "desv"
      ],
      "metadata": {
        "id": "o5JKVBcsN2_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find uncommon values, like greater 2 or 3 times the wiskers\n",
        "X.loc[X['SALDO_ATUAL']> upper_bound, 'SALDO_ATUAL']\n",
        "#there are two lines (127 and 160) that have such values"
      ],
      "metadata": {
        "id": "ZmppdQnAN2_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is confirmed that SALDO_ATUAL has outliers (line 127 and 160)!"
      ],
      "metadata": {
        "id": "cqqSKDBTN2_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get outliers, graphicaly**\n",
        "\n",
        "There are many methods for visualization and finding outliers in data:\n",
        "\n",
        "* Histogram, Scatter Plot\n",
        "* Box plot\n",
        "* Scatter\n",
        "\n",
        "See [Most Common Types of Data Visualization](https://careerfoundry.com/en/blog/data-analytics/data-visualization-types/)"
      ],
      "metadata": {
        "id": "5wLnPwSxNkpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "n2QiM26RNyPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a box-plot\n",
        "fig = px.box(X, x='SALDO_ATUAL')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "IpKBB1iIPsaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correcting Outliers\n",
        "\n",
        "1. Removing affecting rows\n",
        "2. Replacing values\n",
        "\n"
      ],
      "metadata": {
        "id": "33EmmCUPNvjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the affecting rows"
      ],
      "metadata": {
        "id": "SWViZ1s5dUYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X = X.drop([127,160])"
      ],
      "metadata": {
        "id": "kQu_IU4ydTgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X.info()"
      ],
      "metadata": {
        "id": "iYBdO05js8Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X.describe()"
      ],
      "metadata": {
        "id": "4oC19YEVmkq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filePath)"
      ],
      "metadata": {
        "id": "rZLq7WU_sx3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's handle outliers replacing by the median."
      ],
      "metadata": {
        "id": "XCyYajV-OsJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace those values by tje median\n",
        "mediana = X['SALDO_ATUAL'].median()\n",
        "mediana"
      ],
      "metadata": {
        "id": "8ldQ85Xca61Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing with *median*"
      ],
      "metadata": {
        "id": "f6c28q4coyga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[X['SALDO_ATUAL']> upper_bound, 'SALDO_ATUAL']=mediana\n",
        "#check again\n",
        "X.loc[X['SALDO_ATUAL']> upper_bound,'SALDO_ATUAL'].count()\n"
      ],
      "metadata": {
        "id": "mYsB9VeWbOD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output the resultant DAtaframe\n",
        "#X.to_csv(filePath+'newDataSet4.csv',columns=['SALDO_ATUAL'])"
      ],
      "metadata": {
        "id": "O9FF0yaasgkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SALDO_ATUAL now, has no outliers!"
      ],
      "metadata": {
        "id": "daRcdBYnTpFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a box-plot\n",
        "fig = px.box(X, x='SALDO_ATUAL')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bRK7OaRHc45N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c0Ddrnd8N_Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Next Notebook will explore:\n",
        "\n",
        "1. Data Bining\n",
        "2. Categorical to Numeric\n",
        "3. Datasets Manipulation"
      ],
      "metadata": {
        "id": "KdC9Ese22tLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 - References\n",
        "\n",
        "[Complete Guide to Feature Engineering: Zero to Hero](https://www.analyticsvidhya.com/blog/2021/09/complete-guide-to-feature-engineering-zero-to-hero/)"
      ],
      "metadata": {
        "id": "boIeYbMm_i5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "End!"
      ],
      "metadata": {
        "id": "AeB6WWkqj4-z"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}